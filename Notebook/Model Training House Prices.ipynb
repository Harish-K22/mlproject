{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc3efa9-b5ba-418f-a6cc-fe23a50984be",
   "metadata": {},
   "source": [
    "## Model Training House Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21af445-8826-4b9e-b79e-bba8ffb5c0a0",
   "metadata": {},
   "source": [
    "**1.1 Import Data and Required Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d474b5-02bf-4da4-bcac-32bdfa489d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffeff45-588f-4d91-b57b-d617436ca130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "426d01bd-394f-415f-aa36-ecf3377494b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1710</td>\n",
       "      <td>2</td>\n",
       "      <td>856</td>\n",
       "      <td>548</td>\n",
       "      <td>856</td>\n",
       "      <td>8</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>1262</td>\n",
       "      <td>460</td>\n",
       "      <td>1262</td>\n",
       "      <td>6</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1786</td>\n",
       "      <td>2</td>\n",
       "      <td>920</td>\n",
       "      <td>608</td>\n",
       "      <td>920</td>\n",
       "      <td>6</td>\n",
       "      <td>2001</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1717</td>\n",
       "      <td>3</td>\n",
       "      <td>756</td>\n",
       "      <td>642</td>\n",
       "      <td>961</td>\n",
       "      <td>7</td>\n",
       "      <td>1915</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2198</td>\n",
       "      <td>3</td>\n",
       "      <td>1145</td>\n",
       "      <td>836</td>\n",
       "      <td>1145</td>\n",
       "      <td>9</td>\n",
       "      <td>2000</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OverallQual  GrLivArea  GarageCars  TotalBsmtSF  GarageArea  1stFlrSF  \\\n",
       "0            7       1710           2          856         548       856   \n",
       "1            6       1262           2         1262         460      1262   \n",
       "2            7       1786           2          920         608       920   \n",
       "3            7       1717           3          756         642       961   \n",
       "4            8       2198           3         1145         836      1145   \n",
       "\n",
       "   TotRmsAbvGrd  YearBuilt  SalePrice  \n",
       "0             8       2003     208500  \n",
       "1             6       1976     181500  \n",
       "2             6       2001     223500  \n",
       "3             7       1915     140000  \n",
       "4             9       2000     250000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting necessary features\n",
    "selected_features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'GarageArea', '1stFlrSF', 'TotRmsAbvGrd', 'YearBuilt', 'SalePrice']\n",
    "df_selected = df[selected_features]\n",
    "df_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0afbdfb4-cf15-47f3-8852-ecc4e360a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_selected.drop(columns = ['SalePrice'], axis = 1)\n",
    "Y = df_selected['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "788e6f25-270d-491c-b18d-a225325dee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_features = [feature for feature in df_selected.columns if df[feature].dtype != 'O']\n",
    "# categorical_features = [feature for feature in df_selected.columns if df[feature].dtype == 'O']\n",
    "numerical_features = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9234356-9d3f-46cf-a641-af541c114eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding and standard scalar\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# numeric_transformer = StandardScaler()\n",
    "# oh_transformer = OneHotEncoder()\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     [\n",
    "#         (\"OneHotEncoder\", oh_transformer, categorical_features),\n",
    "#          (\"StandardScaler\", numeric_transformer, numerical_features),        \n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2d95951-4236-49e1-9c41-485d143bfe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366e42f8-5f7d-458f-952d-a1d09d656651",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('StandardScaler', numeric_transformer, numerical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a18cdf9-289b-48b2-a347-41debcd8d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4365979-6405-4bc1-ad28-40ee8348e972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c726d3cf-08ab-4b30-b0bc-578b3feb557f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 8), (292, 8))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seperate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37449f9-2cee-4c54-8a83-5dd21777f744",
   "metadata": {},
   "source": [
    "**Create an Evaluate Function to give all metrics after model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e962c0b-2dc9-42e0-bd64-192ac7df845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b727e95-77b3-48ee-8c1a-f038b7ac89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75fc2c30-fed6-4122-9a2a-a3a01c6e37d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 37838.0349\n",
      "- Mean Absolute Error: 24201.2195\n",
      "- R2 Score: 0.7600\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 39610.1215\n",
      "- Mean Absolute Error: 25028.1212\n",
      "- R2 Score: 0.7955\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 37838.0351\n",
      "- Mean Absolute Error: 24200.7906\n",
      "- R2 Score: 0.7600\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 39610.0365\n",
      "- Mean Absolute Error: 25027.5388\n",
      "- R2 Score: 0.7955\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 37838.0492\n",
      "- Mean Absolute Error: 24195.7346\n",
      "- R2 Score: 0.7600\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 39608.9704\n",
      "- Mean Absolute Error: 25022.3609\n",
      "- R2 Score: 0.7955\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 33757.2543\n",
      "- Mean Absolute Error: 21400.8834\n",
      "- R2 Score: 0.8089\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 43360.3716\n",
      "- Mean Absolute Error: 27005.7699\n",
      "- R2 Score: 0.7549\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 848.1564\n",
      "- Mean Absolute Error: 95.3034\n",
      "- R2 Score: 0.9999\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 45895.5803\n",
      "- Mean Absolute Error: 25994.8973\n",
      "- R2 Score: 0.7254\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 12482.9744\n",
      "- Mean Absolute Error: 7688.0828\n",
      "- R2 Score: 0.9739\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 30492.8137\n",
      "- Mean Absolute Error: 19375.0562\n",
      "- R2 Score: 0.8788\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 3098.7116\n",
      "- Mean Absolute Error: 2222.3847\n",
      "- R2 Score: 0.9984\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 32233.4032\n",
      "- Mean Absolute Error: 21233.0983\n",
      "- R2 Score: 0.8645\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 12046.3183\n",
      "- Mean Absolute Error: 9169.0807\n",
      "- R2 Score: 0.9757\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 29522.8326\n",
      "- Mean Absolute Error: 19096.8216\n",
      "- R2 Score: 0.8864\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 29675.9832\n",
      "- Mean Absolute Error: 22688.6331\n",
      "- R2 Score: 0.8524\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 36180.9650\n",
      "- Mean Absolute Error: 25926.2346\n",
      "- R2 Score: 0.8293\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5eb2740-e27d-4fea-ab8e-4d39e0f9230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "params = {\n",
    "    \"Decision Tree\": {\n",
    "        'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [8, 16, 32, 64, 128, 256]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        'learning_rate': [0.1, 0.01, 0.05, 0.001],\n",
    "        'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9],\n",
    "        'n_estimators': [8, 16, 32, 64, 128, 256]\n",
    "    },\n",
    "    \"Linear Regression\": {},\n",
    "    \"Lasso\": {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "    },\n",
    "    \"Ridge\": {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "    },\n",
    "    \"K Neighbors Regressor\": {\n",
    "        'n_neighbors': [5, 10, 15, 20],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "    },\n",
    "    \"XGBRegressor\": {\n",
    "        'learning_rate': [0.1, 0.01, 0.05, 0.001],\n",
    "        'n_estimators': [8, 16, 32, 64, 128, 256]\n",
    "    },\n",
    "    \"CatBoosting Regressor\": {\n",
    "        'depth': [6, 8, 10],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'iterations': [30, 50, 100]\n",
    "    },\n",
    "    \"AdaBoost Regressor\": {\n",
    "        'learning_rate': [0.1, 0.01, 0.5, 0.001],\n",
    "        'n_estimators': [8, 16, 32, 64, 128, 256]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a2351fd-db9d-47ce-8815-7099c6e38eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n",
      "Model: Linear Regression\n",
      "Best Parameters: {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}\n",
      "Train MAE: 24201.2195, Train RMSE: 37838.0349, Train RÂ²: 0.7600\n",
      "Test MAE: 25028.1212, Test RMSE: 39610.1215, Test RÂ²: 0.7955\n",
      "===================================\n",
      "\n",
      "Evaluating Lasso...\n",
      "Model: Lasso\n",
      "Best Parameters: {'alpha': 10.0}\n",
      "Train MAE: 24196.8141, Train RMSE: 37838.0485, Train RÂ²: 0.7600\n",
      "Test MAE: 25022.2654, Test RMSE: 39609.0936, Test RÂ²: 0.7955\n",
      "===================================\n",
      "\n",
      "Evaluating Ridge...\n",
      "Model: Ridge\n",
      "Best Parameters: {'alpha': 10.0}\n",
      "Train MAE: 24150.3353, Train RMSE: 37839.3367, Train RÂ²: 0.7599\n",
      "Test MAE: 24973.7462, Test RMSE: 39600.4592, Test RÂ²: 0.7956\n",
      "===================================\n",
      "\n",
      "Evaluating K-Neighbors Regressor...\n",
      "Model: K-Neighbors Regressor\n",
      "Best Parameters: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
      "Train MAE: 21400.8834, Train RMSE: 33757.2543, Train RÂ²: 0.8089\n",
      "Test MAE: 27005.7699, Test RMSE: 43360.3716, Test RÂ²: 0.7549\n",
      "===================================\n",
      "\n",
      "Evaluating Decision Tree...\n",
      "Model: Decision Tree\n",
      "Best Parameters: {'criterion': 'squared_error'}\n",
      "Train MAE: 95.3034, Train RMSE: 848.1564, Train RÂ²: 0.9999\n",
      "Test MAE: 25736.7089, Test RMSE: 39671.8719, Test RÂ²: 0.7948\n",
      "===================================\n",
      "\n",
      "Evaluating Random Forest Regressor...\n",
      "Model: Random Forest Regressor\n",
      "Best Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Train MAE: 7670.2953, Train RMSE: 12463.1490, Train RÂ²: 0.9740\n",
      "Test MAE: 19106.5333, Test RMSE: 29769.2027, Test RÂ²: 0.8845\n",
      "===================================\n",
      "\n",
      "Evaluating XGBRegressor...\n",
      "Model: XGBRegressor\n",
      "Best Parameters: {'learning_rate': 0.05, 'n_estimators': 128}\n",
      "Train MAE: 9528.0848, Train RMSE: 12897.3954, Train RÂ²: 0.9721\n",
      "Test MAE: 20095.4696, Test RMSE: 31010.4329, Test RÂ²: 0.8746\n",
      "===================================\n",
      "\n",
      "Evaluating CatBoosting Regressor...\n",
      "Model: CatBoosting Regressor\n",
      "Best Parameters: {'depth': 10, 'iterations': 100, 'learning_rate': 0.1}\n",
      "Train MAE: 12693.4762, Train RMSE: 17329.4815, Train RÂ²: 0.9497\n",
      "Test MAE: 19130.8879, Test RMSE: 29845.0122, Test RÂ²: 0.8839\n",
      "===================================\n",
      "\n",
      "Evaluating AdaBoost Regressor...\n",
      "Model: AdaBoost Regressor\n",
      "Best Parameters: {'learning_rate': 0.1, 'n_estimators': 256}\n",
      "Train MAE: 22572.3507, Train RMSE: 29988.9442, Train RÂ²: 0.8492\n",
      "Test MAE: 25387.6466, Test RMSE: 35586.7494, Test RÂ²: 0.8349\n",
      "===================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_models(X_train, y_train, X_test, y_test, models, params):\n",
    "    model_list = []\n",
    "    train_metrics = []\n",
    "    test_metrics = []\n",
    "    \n",
    "    # Filter out specific warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "    # Iterate over models and perform GridSearchCV with hyperparameter tuning\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        \n",
    "        if model_name in params:\n",
    "            param_grid = params[model_name]\n",
    "        else:\n",
    "            param_grid = {}\n",
    "\n",
    "        if param_grid:\n",
    "            grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_root_mean_squared_error', cv=5)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            # Best parameters and best score\n",
    "            best_params = grid_search.best_params_\n",
    "            best_model = grid_search.best_estimator_\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            best_params = model.get_params()\n",
    "            best_model = model\n",
    "\n",
    "        # Fit the model with the best parameters\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on training and test sets\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Calculate evaluation metrics for training and test sets\n",
    "        train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        \n",
    "        test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "        # Store model name and evaluation metrics\n",
    "        model_list.append(model_name)\n",
    "        train_metrics.append((train_mae, train_rmse, train_r2))\n",
    "        test_metrics.append((test_mae, test_rmse, test_r2))\n",
    "\n",
    "        # Print model performance\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Best Parameters: {best_params}\")\n",
    "        print(f\"Train MAE: {train_mae:.4f}, Train RMSE: {train_rmse:.4f}, Train RÂ²: {train_r2:.4f}\")\n",
    "        print(f\"Test MAE: {test_mae:.4f}, Test RMSE: {test_rmse:.4f}, Test RÂ²: {test_r2:.4f}\")\n",
    "        print('=' * 35)\n",
    "        print()\n",
    "\n",
    "    # Create and return a report dictionary\n",
    "    model_report = {\n",
    "        'model_list': model_list,\n",
    "        'train_metrics': train_metrics,\n",
    "        'test_metrics': test_metrics\n",
    "    }\n",
    "    \n",
    "    return model_report\n",
    "\n",
    "# Evaluate models\n",
    "model_report = evaluate_models(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, models=models, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70753d-481b-4e4f-b73b-06fcb7128fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Load train.csv and test.csv\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Selecting specific features for training and testing\n",
    "selected_features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'GarageArea', \n",
    "                     '1stFlrSF', 'TotRmsAbvGrd', 'YearBuilt', 'SalePrice']\n",
    "\n",
    "# Separate features and target from train.csv\n",
    "X_train = df_train[selected_features].drop(columns=['SalePrice'], axis=1)\n",
    "y_train = df_train['SalePrice']\n",
    "\n",
    "# Separate features from test.csv\n",
    "X_test = df_test[selected_features[:-1]]  # Adjust here if needed based on actual columns in test.csv\n",
    "\n",
    "# Define numerical features\n",
    "numerical_features = X_train.columns.tolist()\n",
    "\n",
    "# Define transformer for numerical features with imputation\n",
    "numeric_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_features)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing to train and test data\n",
    "X_train_transformed = numeric_transformer.fit_transform(X_train)\n",
    "X_test_transformed = numeric_transformer.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "\n",
    "# Train models and predict on test data\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_transformed, y_train)\n",
    "    y_test_pred = model.predict(X_test_transformed)\n",
    "    \n",
    "    # Create output DataFrame for each model\n",
    "    output = pd.DataFrame({'Id': df_test['Id'], 'SalePrice': y_test_pred})\n",
    "    \n",
    "    # Save output to CSV\n",
    "    output.to_csv(f'{model_name}_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fe80b8f-bd7c-4939-a162-a8bc82bb8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Load train.csv and test.csv\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Selecting specific features for training and testing\n",
    "selected_features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'GarageArea', \n",
    "                     '1stFlrSF', 'TotRmsAbvGrd', 'YearBuilt', 'SalePrice']\n",
    "\n",
    "# Separate features and target from train.csv\n",
    "X_train = df_train[selected_features].drop(columns=['SalePrice'], axis=1)\n",
    "y_train = df_train['SalePrice']\n",
    "\n",
    "# Separate features from test.csv\n",
    "X_test = df_test[selected_features[:-1]]  # Adjust here if needed based on actual columns in test.csv\n",
    "\n",
    "# Define numerical features\n",
    "numerical_features = X_train.columns.tolist()\n",
    "\n",
    "# Define transformer for numerical features with imputation\n",
    "numeric_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_features)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing to train and test data\n",
    "X_train_transformed = numeric_transformer.fit_transform(X_train)\n",
    "X_test_transformed = numeric_transformer.transform(X_test)\n",
    "\n",
    "# Define best parameters found for each model\n",
    "best_params = {\n",
    "    \"Linear Regression\": {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False},\n",
    "    \"Lasso\": {'alpha': 10.0},\n",
    "    \"Ridge\": {'alpha': 10.0},\n",
    "    \"K-Neighbors Regressor\": {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'},\n",
    "    \"Decision Tree\": {'criterion': 'squared_error'},\n",
    "    \"Random Forest Regressor\": {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False},\n",
    "    \"XGBRegressor\": {'learning_rate': 0.05, 'n_estimators': 128},\n",
    "    \"CatBoosting Regressor\": {'depth': 10, 'iterations': 100, 'learning_rate': 0.1},\n",
    "    \"AdaBoost Regressor\": {'learning_rate': 0.1, 'n_estimators': 256}\n",
    "}\n",
    "\n",
    "# Initialize models with best parameters\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(**best_params[\"Linear Regression\"]),\n",
    "    \"Lasso\": Lasso(**best_params[\"Lasso\"]),\n",
    "    \"Ridge\": Ridge(**best_params[\"Ridge\"]),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(**best_params[\"K-Neighbors Regressor\"]),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(**best_params[\"Decision Tree\"]),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(**best_params[\"Random Forest Regressor\"]),\n",
    "    \"XGBRegressor\": XGBRegressor(**best_params[\"XGBRegressor\"]), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False, **best_params[\"CatBoosting Regressor\"]),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(**best_params[\"AdaBoost Regressor\"])\n",
    "}\n",
    "\n",
    "# Train models and predict on test data\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_transformed, y_train)\n",
    "    y_test_pred = model.predict(X_test_transformed)\n",
    "    \n",
    "    # Create output DataFrame for each model\n",
    "    output = pd.DataFrame({'Id': df_test['Id'], 'SalePrice': y_test_pred})\n",
    "    \n",
    "    # Save output to CSV\n",
    "    output.to_csv(f'{model_name}_predictions_hyperparameter_tuning.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b133b-538e-47a4-b2f3-041255d9db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best score - 0.15914"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
